grid_0 (Oct 19, 2016):

* I ran a grid from 0.2Msun to 1.4Msun, and 1/10th solar to 10x solar. I
  stepped it by 0.2Msun in mass, and 0.5dex in metallicity (total: 30 stars).
* I put a maximum age as 11Gyr, and let them run for 3 hours (a single core
  each) on adroit. I can do up to 60 stars at a time this way (i.e. I get at
  most 60 cores at a time. The submission is pretty cool -- I've structured it
  so that queue times are typically <5 minutes). Many stars reach the max age
  within ~30minutes clock time, but many others (e.g., massive stars) do not.
* Once you get past the main sequence, through the subgiant branch and into the
  red giant branch the adaptive timestep becomes very short and the evolution
  doesn't get past the max age you can see in the plots. There might be some
  dependence of metallicity on this too -- I haven't looked through that data
  yet.
* My write-frequency for the stellar models is a multiple of the timesteps, and
  I have a hard-cap on the maximum number of models to save from any given
  star. Then they start overwriting the initial data from the run. This is what
  some of the attached plots are missing data in their early lives (I'm also
  only processing data from past 0.5Myr).



grid_1 (Nov 1, 2016):

Tried a run with `log_L_upper_limit = 1.5`. This was a problem (i.e. it
terminated models too early) during early contraction (at <5e5 years, which I
wasn't plotting in postprocessing but which I'm still computing).
The similar naive idea, which is to say `photosphere_r_upper_limit = 3.0`
will produce the same problem.
Other ideas:
  log_center_density_limit 
  he_core_mass_limit 
  log_L_upper_limit (note docs say "in order to skip pre-ms, this limit only
    applies when L_nuc > 0.01*L")
  log_g_lower_limit ! stop when log10(gravity at surface) is less than this
    limit.
  power_he_burn_upper_limit ! stop when total power from reactions burning
    helium (in Lsun units) is > this.


